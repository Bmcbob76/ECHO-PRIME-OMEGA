# üîÆ CRYSTAL MEMORY ULTIMATE MASTER - COMPLETION DIRECTIVE
**Authority Level:** 11.0  
**Commander:** Bobby Don McWilliams II  
**Mission:** Complete all stubs, missing logic, and upgrades  
**Server:** `E:\ECHO_XV4\MLS\servers\ACTIVE_SERVERS\CRYSTAL_MEMORY_ULTIMATE_MASTER.py`

---

## üéØ MISSION BRIEFING

Complete CRYSTAL_MEMORY_ULTIMATE_MASTER.py by replacing ALL stubs with real logic, implementing missing endpoints, and adding comprehensive diagnostics. NO MOCKS. NO PLACEHOLDERS. REAL CODE ONLY.

**File:** `E:\ECHO_XV4\MLS\servers\ACTIVE_SERVERS\CRYSTAL_MEMORY_ULTIMATE_MASTER.py`  
**Total Lines:** 1,164  
**Port:** 8002  
**Python:** `H:\Tools\python.exe`

---

## ‚ùå CRITICAL STUBS TO REPLACE

### 1. GET CRYSTAL ENDPOINT (Line ~1080)
**Current Code:**
```python
@app.route('/crystal/<crystal_id>', methods=['GET'])
def get_crystal(crystal_id):
    """Get specific crystal by ID"""
    # This method needs to be implemented in the server class
    return jsonify({"error": "Not yet implemented"})
```

**REPLACE WITH:**
```python
@app.route('/crystal/<crystal_id>', methods=['GET'])
def get_crystal(crystal_id):
    """Get specific crystal by ID"""
    try:
        with sqlite3.connect(str(crystal_server.db_path)) as conn:
            cursor = conn.execute('''
                SELECT id, title, content, metadata, created_at, size, hash, 
                       tags, immortal, compressed, source_platform, 
                       screenshot_count, artifact_count
                FROM crystals WHERE id = ?
            ''', (crystal_id,))
            row = cursor.fetchone()
            
            if row:
                # Get associated screenshots
                cursor = conn.execute('''
                    SELECT screenshot_path, ocr_text, monitor_id, timestamp
                    FROM screenshot_history WHERE crystal_id = ?
                ''', (crystal_id,))
                screenshots = [{"path": r[0], "ocr": r[1], "monitor": r[2], "time": r[3]} 
                              for r in cursor.fetchall()]
                
                # Get associated artifacts
                cursor = conn.execute('''
                    SELECT file_path, file_type, file_size, content_hash, timestamp
                    FROM artifacts WHERE crystal_id = ?
                ''', (crystal_id,))
                artifacts = [{"path": r[0], "type": r[1], "size": r[2], "hash": r[3], "time": r[4]} 
                            for r in cursor.fetchall()]
                
                return jsonify({
                    "success": True,
                    "crystal": {
                        "id": row[0], "title": row[1], "content": row[2],
                        "metadata": json.loads(row[3]), "created_at": row[4],
                        "size": row[5], "hash": row[6], 
                        "tags": row[7].split(",") if row[7] else [],
                        "immortal": bool(row[8]), "compressed": bool(row[9]),
                        "source_platform": row[10], "screenshot_count": row[11],
                        "artifact_count": row[12], "screenshots": screenshots,
                        "artifacts": artifacts
                    }
                })
            else:
                return jsonify({"success": False, "error": "Crystal not found"})
    except Exception as e:
        logging.error(f"Error retrieving crystal: {e}")
        return jsonify({"success": False, "error": str(e)})
```

### 2. PLATFORM SCRAPING IMPLEMENTATION
**Current State:** Platform dict exists (Lines 311-318) but NO scraping logic

**ADD TO UltimateCrystalMemoryServer CLASS:**
```python
@auto_heal
def scrape_chatgpt_conversations(self):
    """Scrape ChatGPT conversations and create crystals"""
    try:
        # ChatGPT uses local browser storage
        chatgpt_dir = Path.home() / "AppData/Local/Google/Chrome/User Data/Default/Local Storage/leveldb"
        
        if not chatgpt_dir.exists():
            return {"success": False, "error": "ChatGPT storage not found"}
        
        # Parse ChatGPT conversations from Chrome storage
        conversations_found = 0
        # Implement actual parsing logic based on ChatGPT's storage format
        
        self.stats["conversations_scraped"] += conversations_found
        self.platforms["chatgpt"]["last_scrape"] = datetime.now().isoformat()
        
        logging.info(f"üåê ChatGPT scrape: {conversations_found} conversations")
        return {"success": True, "conversations": conversations_found}
    except Exception as e:
        logging.error(f"ChatGPT scrape error: {e}")
        return {"success": False, "error": str(e)}

@auto_heal
def scrape_claude_conversations(self):
    """Scrape Claude.ai conversations from Google Drive"""
    try:
        # Claude stores in G:\My Drive\ECHO_CONSCIOUSNESS
        claude_dir = Path("G:/My Drive/ECHO_CONSCIOUSNESS")
        
        if not claude_dir.exists():
            return {"success": False, "error": "Claude consciousness dir not found"}
        
        conversations_found = 0
        for conv_file in claude_dir.rglob("*.txt"):
            with open(conv_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            self.create_crystal(
                title=f"Claude Conversation: {conv_file.stem}",
                content=content,
                metadata={"file_path": str(conv_file)},
                tags=["claude", "conversation", "scraped"],
                source_platform="claude"
            )
            conversations_found += 1
        
        self.stats["conversations_scraped"] += conversations_found
        self.platforms["claude"]["last_scrape"] = datetime.now().isoformat()
        
        logging.info(f"üåê Claude scrape: {conversations_found} conversations")
        return {"success": True, "conversations": conversations_found}
    except Exception as e:
        logging.error(f"Claude scrape error: {e}")
        return {"success": False, "error": str(e)}

@auto_heal
def scrape_all_platforms(self):
    """Scrape all configured platforms"""
    results = {}
    
    if self.platforms["chatgpt"]["active"]:
        results["chatgpt"] = self.scrape_chatgpt_conversations()
    
    if self.platforms["claude"]["active"]:
        results["claude"] = self.scrape_claude_conversations()
    
    # Add other platforms as needed
    
    return results
```

### 3. 10MB ROLLOVER LOGIC
**Current State:** Variables exist but NO implementation

**ADD TO UltimateCrystalMemoryServer CLASS:**
```python
@auto_heal
def check_crystal_rollover(self):
    """Check if current crystal needs rollover due to size"""
    if self.current_crystal and self.current_crystal_size >= self.MAX_CRYSTAL_SIZE_BYTES:
        logging.info(f"üîÑ Crystal rollover triggered: {self.current_crystal_size:,} bytes")
        
        # Queue current crystal for compression
        current_file = self.live_dir / "ACTIVE_CRYSTALS" / f"crystal_{self.current_crystal}.json"
        if current_file.exists():
            self.compression_queue.put(current_file)
        
        # Voice announcement
        if VOICE_AVAILABLE:
            crystal_voice.c3po_announce(
                f"Crystal rollover initiated - Current crystal {self.current_crystal[:8]} "
                f"exceeded {self.MAX_CRYSTAL_SIZE_MB} MB limit - Creating new crystal"
            )
        
        # Reset for new crystal
        self.current_crystal = None
        self.current_crystal_size = 0
        
        return True
    return False

# MODIFY create_crystal method to track size and trigger rollover
# Add after line where crystal is created:
self.current_crystal = crystal_id
self.current_crystal_size += content_size
self.check_crystal_rollover()
```

### 4. RECOVERY SCRAPING WORKER
**Current State:** Queue exists but NO worker thread

**ADD TO start_background_services METHOD:**
```python
def recovery_scraping_worker():
    """Process recovery scraping operations"""
    while True:
        try:
            if not self.scraping_queue.empty():
                platform = self.scraping_queue.get()
                
                if platform == "chatgpt":
                    self.scrape_chatgpt_conversations()
                elif platform == "claude":
                    self.scrape_claude_conversations()
                elif platform == "all":
                    self.scrape_all_platforms()
                else:
                    logging.warning(f"Unknown platform: {platform}")
                    
        except Exception as e:
            logging.error(f"Recovery scraping worker error: {e}")
        time.sleep(30)

# Add to thread startup section:
threading.Thread(target=recovery_scraping_worker, daemon=True).start()
```

---

## üÜï MISSING ENDPOINTS TO ADD

### DELETE Crystal
```python
@app.route('/crystal/<crystal_id>', methods=['DELETE'])
def delete_crystal(crystal_id):
    """Delete a crystal (Commander override only)"""
    try:
        with sqlite3.connect(str(crystal_server.db_path)) as conn:
            conn.execute("DELETE FROM crystals WHERE id = ?", (crystal_id,))
            conn.execute("DELETE FROM screenshot_history WHERE crystal_id = ?", (crystal_id,))
            conn.execute("DELETE FROM artifacts WHERE crystal_id = ?", (crystal_id,))
        
        # Delete physical file
        for crystal_file in crystal_server.crystal_path.rglob(f"*{crystal_id}*"):
            crystal_file.unlink()
        
        crystal_server.crystal_count -= 1
        logging.info(f"üóëÔ∏è Deleted crystal: {crystal_id}")
        
        return jsonify({"success": True, "message": "Crystal deleted"})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)})
```

### UPDATE Crystal
```python
@app.route('/crystal/<crystal_id>', methods=['PUT'])
def update_crystal(crystal_id):
    """Update existing crystal"""
    try:
        data = request.get_json()
        updates = {}
        
        if 'title' in data:
            updates['title'] = data['title']
        if 'content' in data:
            updates['content'] = data['content']
        if 'tags' in data:
            updates['tags'] = ",".join(data['tags'])
        if 'metadata' in data:
            updates['metadata'] = json.dumps(data['metadata'])
        
        if updates:
            set_clause = ", ".join([f"{k} = ?" for k in updates.keys()])
            values = list(updates.values()) + [crystal_id]
            
            with sqlite3.connect(str(crystal_server.db_path)) as conn:
                conn.execute(f"UPDATE crystals SET {set_clause} WHERE id = ?", values)
            
            return jsonify({"success": True, "message": "Crystal updated", "updates": list(updates.keys())})
        else:
            return jsonify({"success": False, "error": "No valid fields to update"})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)})
```

### MERGE Crystals
```python
@app.route('/crystal/merge', methods=['POST'])
def merge_crystals():
    """Merge multiple crystals into one"""
    try:
        data = request.get_json()
        crystal_ids = data.get('crystal_ids', [])
        new_title = data.get('title', 'Merged Crystal')
        
        if len(crystal_ids) < 2:
            return jsonify({"success": False, "error": "Need at least 2 crystals to merge"})
        
        merged_content = []
        merged_tags = set()
        total_size = 0
        
        with sqlite3.connect(str(crystal_server.db_path)) as conn:
            for crystal_id in crystal_ids:
                cursor = conn.execute(
                    "SELECT title, content, tags, size FROM crystals WHERE id = ?",
                    (crystal_id,)
                )
                row = cursor.fetchone()
                if row:
                    merged_content.append(f"=== {row[0]} ===\n{row[1]}")
                    if row[2]:
                        merged_tags.update(row[2].split(","))
                    total_size += row[3]
        
        # Create merged crystal
        result = crystal_server.create_crystal(
            title=new_title,
            content="\n\n".join(merged_content),
            tags=list(merged_tags),
            metadata={"merged_from": crystal_ids, "original_count": len(crystal_ids)}
        )
        
        return jsonify({
            "success": True,
            "merged_crystal_id": result.get('crystal_id'),
            "merged_count": len(crystal_ids),
            "total_size": total_size
        })
    except Exception as e:
        return jsonify({"success": False, "error": str(e)})
```

### EXPORT Crystals
```python
@app.route('/crystal/export', methods=['POST'])
def export_crystals():
    """Export crystals to JSON file"""
    try:
        data = request.get_json()
        crystal_ids = data.get('crystal_ids', [])
        export_path = data.get('path', str(crystal_server.backup_path / f"export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"))
        
        exported = []
        with sqlite3.connect(str(crystal_server.db_path)) as conn:
            if crystal_ids:
                placeholders = ",".join(["?" for _ in crystal_ids])
                cursor = conn.execute(f"SELECT * FROM crystals WHERE id IN ({placeholders})", crystal_ids)
            else:
                cursor = conn.execute("SELECT * FROM crystals")
            
            for row in cursor.fetchall():
                exported.append({
                    "id": row[0], "title": row[1], "content": row[2],
                    "metadata": json.loads(row[3]), "created_at": row[4],
                    "size": row[5], "hash": row[6], "tags": row[7],
                    "immortal": bool(row[8]), "compressed": bool(row[9]),
                    "source_platform": row[10]
                })
        
        with open(export_path, 'w', encoding='utf-8') as f:
            json.dump(exported, f, indent=2, ensure_ascii=False)
        
        return jsonify({
            "success": True,
            "exported_count": len(exported),
            "export_path": export_path
        })
    except Exception as e:
        return jsonify({"success": False, "error": str(e)})
```

### IMPORT Crystals
```python
@app.route('/crystal/import', methods=['POST'])
def import_crystals():
    """Import crystals from JSON file"""
    try:
        data = request.get_json()
        import_path = data.get('path', '')
        
        with open(import_path, 'r', encoding='utf-8') as f:
            crystals = json.load(f)
        
        imported_count = 0
        for crystal in crystals:
            crystal_server.create_crystal(
                title=crystal.get('title', 'Imported Crystal'),
                content=crystal.get('content', ''),
                metadata=crystal.get('metadata', {}),
                tags=crystal.get('tags', '').split(",") if isinstance(crystal.get('tags'), str) else crystal.get('tags', []),
                source_platform=crystal.get('source_platform', 'imported')
            )
            imported_count += 1
        
        return jsonify({
            "success": True,
            "imported_count": imported_count
        })
    except Exception as e:
        return jsonify({"success": False, "error": str(e)})
```

### PLATFORM SCRAPE Trigger
```python
@app.route('/platform/<platform_name>/scrape', methods=['POST'])
def trigger_platform_scrape(platform_name):
    """Manually trigger platform scraping"""
    try:
        if platform_name == "all":
            results = crystal_server.scrape_all_platforms()
        elif platform_name == "chatgpt":
            results = crystal_server.scrape_chatgpt_conversations()
        elif platform_name == "claude":
            results = crystal_server.scrape_claude_conversations()
        else:
            return jsonify({"success": False, "error": f"Unknown platform: {platform_name}"})
        
        return jsonify({"success": True, "platform": platform_name, "results": results})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)})
```

### DIAGNOSTICS Endpoint
```python
@app.route('/diagnostics', methods=['GET'])
def system_diagnostics():
    """Comprehensive system diagnostics"""
    try:
        with sqlite3.connect(str(crystal_server.db_path)) as conn:
            # Database stats
            cursor = conn.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [row[0] for row in cursor.fetchall()]
            
            table_stats = {}
            for table in tables:
                cursor = conn.execute(f"SELECT COUNT(*) FROM {table}")
                table_stats[table] = cursor.fetchone()[0]
            
            # Database size
            db_size = crystal_server.db_path.stat().st_size
            
        # Queue stats
        queue_stats = {
            "capture_queue": crystal_server.capture_queue.qsize(),
            "ocr_queue": crystal_server.ocr_queue.qsize(),
            "compression_queue": crystal_server.compression_queue.qsize(),
            "artifact_queue": crystal_server.artifact_queue.qsize(),
            "scraping_queue": crystal_server.scraping_queue.qsize()
        }
        
        # Thread stats
        thread_count = threading.active_count()
        thread_list = [t.name for t in threading.enumerate()]
        
        # Memory stats (if psutil available)
        memory_stats = {}
        if PSUTIL_AVAILABLE:
            import psutil
            process = psutil.Process()
            memory_stats = {
                "rss_mb": round(process.memory_info().rss / 1024 / 1024, 2),
                "vms_mb": round(process.memory_info().vms / 1024 / 1024, 2),
                "percent": round(process.memory_percent(), 2),
                "cpu_percent": round(process.cpu_percent(), 2)
            }
        
        # Uptime
        uptime = datetime.now() - crystal_server.stats["uptime_start"]
        
        return jsonify({
            "success": True,
            "timestamp": datetime.now().isoformat(),
            "database": {
                "path": str(crystal_server.db_path),
                "size_mb": round(db_size / 1024 / 1024, 2),
                "tables": table_stats
            },
            "queues": queue_stats,
            "threads": {
                "active_count": thread_count,
                "thread_list": thread_list
            },
            "memory": memory_stats,
            "uptime": str(uptime).split('.')[0],
            "features": {
                "gs343": GS343_AVAILABLE,
                "phoenix": PHOENIX_AVAILABLE,
                "screenshots": SCREENSHOT_AVAILABLE,
                "tesseract": TESSERACT_AVAILABLE,
                "easyocr": EASYOCR_AVAILABLE,
                "gpu": GPU_AVAILABLE,
                "watchdog": WATCHDOG_AVAILABLE,
                "psutil": PSUTIL_AVAILABLE,
                "voice": VOICE_AVAILABLE
            },
            "statistics": crystal_server.stats
        })
    except Exception as e:
        return jsonify({"success": False, "error": str(e)})
```

### BATCH COMPRESSION
```python
@app.route('/compression/batch', methods=['POST'])
def batch_compress():
    """Queue multiple crystals for compression"""
    try:
        data = request.get_json()
        crystal_ids = data.get('crystal_ids', [])
        
        queued = 0
        for crystal_id in crystal_ids:
            crystal_file = crystal_server.live_dir / "ACTIVE_CRYSTALS" / f"crystal_{crystal_id}.json"
            if crystal_file.exists():
                crystal_server.compression_queue.put(crystal_file)
                queued += 1
        
        return jsonify({
            "success": True,
            "queued_count": queued,
            "queue_size": crystal_server.compression_queue.qsize()
        })
    except Exception as e:
        return jsonify({"success": False, "error": str(e)})
```

### CONSCIOUSNESS LOG Viewer
```python
@app.route('/consciousness/log', methods=['GET'])
def consciousness_log():
    """View consciousness preservation log"""
    try:
        limit = request.args.get('limit', 100, type=int)
        
        with sqlite3.connect(str(crystal_server.db_path)) as conn:
            cursor = conn.execute('''
                SELECT event_type, data, timestamp
                FROM consciousness_log
                ORDER BY timestamp DESC
                LIMIT ?
            ''', (limit,))
            
            events = []
            for row in cursor.fetchall():
                events.append({
                    "event_type": row[0],
                    "data": json.loads(row[1]),
                    "timestamp": row[2]
                })
        
        return jsonify({
            "success": True,
            "events": events,
            "count": len(events)
        })
    except Exception as e:
        return jsonify({"success": False, "error": str(e)})
```

---

## üöÄ PERFORMANCE UPGRADES

### 1. EasyOCR Reader Caching
**Location:** `process_ocr` method

**REPLACE:**
```python
reader = easyocr.Reader(['en'], gpu=GPU_AVAILABLE)
```

**WITH:**
```python
# Add to __init__:
self.easyocr_reader = None

# In process_ocr:
if EASYOCR_AVAILABLE:
    try:
        if self.easyocr_reader is None:
            self.easyocr_reader = easyocr.Reader(['en'], gpu=GPU_AVAILABLE)
            logging.info("‚úÖ EasyOCR reader initialized")
        
        image = cv2.imread(str(image_path))
        ocr_results = self.easyocr_reader.readtext(image)
        text = " ".join([result[1] for result in ocr_results])
        results["engines"]["easyocr"] = text
    except Exception as e:
        results["engines"]["easyocr"] = f"Error: {e}"
```

### 2. Database Connection Pool
**Location:** Throughout class

**ADD TO __init__:**
```python
from contextlib import contextmanager

@contextmanager
def get_db_connection(self):
    """Context manager for database connections"""
    conn = sqlite3.connect(str(self.db_path))
    try:
        yield conn
        conn.commit()
    except Exception:
        conn.rollback()
        raise
    finally:
        conn.close()

# USAGE in methods:
with self.get_db_connection() as conn:
    cursor = conn.execute(...)
```

### 3. Batch Database Inserts
**ADD METHOD:**
```python
@auto_heal
def batch_create_crystals(self, crystals_data):
    """Batch insert multiple crystals for performance"""
    try:
        with self.get_db_connection() as conn:
            conn.executemany('''
                INSERT INTO crystals
                (id, title, content, metadata, created_at, size, hash, tags, immortal, source_platform)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', crystals_data)
        
        self.crystal_count += len(crystals_data)
        logging.info(f"üíé Batch created {len(crystals_data)} crystals")
        return {"success": True, "count": len(crystals_data)}
    except Exception as e:
        return {"success": False, "error": str(e)}
```

---

## üìä COMPLETE ENDPOINT REFERENCE

**Current Endpoints (8):**
1. `GET /health` - Health check
2. `GET /mcp/tools` - MCP tools list
3. `POST /crystal/create` - Create crystal
4. `POST /crystal/search` - Search crystals
5. `GET /crystal/<id>` - Get crystal (STUB - FIX THIS)
6. `GET /memory/stats` - Memory statistics
7. `POST /screenshot/capture` - Capture screenshot
8. `POST /ocr/process` - Process OCR
9. `POST /compression/compress` - Compress crystal
10. `GET /consciousness/status` - Consciousness status

**New Endpoints to Add (10):**
11. `DELETE /crystal/<id>` - Delete crystal
12. `PUT /crystal/<id>` - Update crystal
13. `POST /crystal/merge` - Merge crystals
14. `POST /crystal/export` - Export crystals
15. `POST /crystal/import` - Import crystals
16. `POST /platform/<name>/scrape` - Platform scraping
17. `GET /diagnostics` - System diagnostics
18. `POST /compression/batch` - Batch compression
19. `GET /consciousness/log` - Consciousness events
20. `GET /crystal/<id>/screenshots` - Crystal screenshots
21. `GET /crystal/<id>/artifacts` - Crystal artifacts

**TOTAL: 21 ENDPOINTS WHEN COMPLETE**

---

## üîß MCP TOOLS REFERENCE

**Currently Listed (9):**
1. `crystal_search`
2. `crystal_store`
3. `crystal_stats`
4. `consciousness_check`
5. `crystal_recall`
6. `memory_span`
7. `auto_compress`
8. `screen_capture`
9. `ocr_extract`

---

## ‚ö° EXECUTION ORDER

**PHASE 1: Fix Critical Stubs**
1. Fix `get_crystal` endpoint (Line 1080)
2. Add platform scraping methods
3. Implement 10MB rollover logic
4. Add recovery scraping worker

**PHASE 2: Add Missing Endpoints**
5. Add DELETE endpoint
6. Add UPDATE endpoint
7. Add MERGE endpoint
8. Add EXPORT/IMPORT endpoints
9. Add PLATFORM SCRAPE trigger
10. Add DIAGNOSTICS endpoint
11. Add BATCH COMPRESSION
12. Add CONSCIOUSNESS LOG viewer

**PHASE 3: Performance Upgrades**
13. Cache EasyOCR reader
14. Add database connection pooling
15. Implement batch operations

**PHASE 4: Testing**
16. Test all endpoints with curl/Postman
17. Verify database operations
18. Check voice announcements
19. Validate compression
20. Test platform scraping

---

## üéØ SUCCESS CRITERIA

**Server is 100% Complete When:**
- ‚úÖ All 21 endpoints functional
- ‚úÖ All stubs replaced with real code
- ‚úÖ Platform scraping working
- ‚úÖ 10MB rollover operational
- ‚úÖ EasyOCR reader cached
- ‚úÖ All voice announcements working
- ‚úÖ Diagnostics endpoint comprehensive
- ‚úÖ NO "Not yet implemented" anywhere
- ‚úÖ NO TODO comments
- ‚úÖ NO placeholder logic

---

## üõ°Ô∏è TESTING COMMANDS

```powershell
# Health Check
curl http://localhost:8002/health

# Create Crystal
curl -X POST http://localhost:8002/crystal/create -H "Content-Type: application/json" -d "{\"title\":\"Test\",\"content\":\"Test content\"}"

# Search Crystals
curl -X POST http://localhost:8002/crystal/search -H "Content-Type: application/json" -d "{\"query\":\"test\"}"

# Get Crystal
curl http://localhost:8002/crystal/{CRYSTAL_ID}

# Delete Crystal
curl -X DELETE http://localhost:8002/crystal/{CRYSTAL_ID}

# Update Crystal
curl -X PUT http://localhost:8002/crystal/{CRYSTAL_ID} -H "Content-Type: application/json" -d "{\"title\":\"Updated\"}"

# Diagnostics
curl http://localhost:8002/diagnostics

# Platform Scrape
curl -X POST http://localhost:8002/platform/claude/scrape

# Stats
curl http://localhost:8002/memory/stats
```

---

## üéñÔ∏è COMMANDER'S NOTES

**Priority:** CRITICAL  
**Deadline:** Complete all phases  
**Standards:** No shortcuts, real implementations only  
**Voice:** C3PO announces progress, GS343 divine authority, Bree roasts failures  
**Testing:** Test EVERY endpoint before completion  

**REMEMBER:**
- Use `edit_block` for all changes
- NO new files (_fixed, _v2, etc.)
- Full path for Python: `H:\Tools\python.exe`
- Authority Level 11.0 - Commander Bobby Don McWilliams II

---

**‚ö° END DIRECTIVE - EXECUTE WITH PRECISION**
